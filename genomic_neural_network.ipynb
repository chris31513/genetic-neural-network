# Redes neuronales
## Equipo 06

# Introducción

# Objetivo

# Hipótesis

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "genomic_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me1v7n5ml7zz"
      },
      "source": [
        "La red que vamos a construir toma datos de un dataset que contiene toda la información genética que Manu Sporny logró recabar usando varias marcas genéticas. Con base en esas marcas genéticas vamos a clasificar cada una en diferentes genotipos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xutdwq0ujk14"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch as pt\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt \n",
        "import random\n",
        "\n",
        "# leemos el archivo\n",
        "\n",
        "f = open('ManuSporny-genome.txt', 'r')\n",
        "all_lines = f.read().split('\\n')\n",
        "lines_without_comments = list(filter(lambda x: len(x) > 0 and x[0] != '#', all_lines))\n",
        "lines_to_rows = list(map(lambda x: x.split('\\t'), lines_without_comments))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X76DmJCvu-iD"
      },
      "source": [
        "El conjunto de datos está dividido en 3 columnas de datos genéticos; rsid, chromosoma, posición. Y una última columna que es la clasificación del genotipo de cada renglón."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV8Y2EBrvOY_"
      },
      "source": [
        "# clasificamos las entradas y salidas de la red\n",
        "\n",
        "chromosome = [row[1] for row in lines_to_rows]\n",
        "\n",
        "genotypes = [row[3] for row in lines_to_rows]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZHb7mF6vTHK"
      },
      "source": [
        "Aunque todos los datos son números, la red puede llegar a confundirse y no encontrar ninguna relación entre estos, así que, como será una red clasificadora, debemos separar el conjunto usando one-hot-encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR0rxoX1xg3E"
      },
      "source": [
        "# obtenemos todas las clases\n",
        "\n",
        "chromosome_classes = list(set(chromosome))\n",
        "\n",
        "genotypes_classes = list(set(genotypes))\n",
        "\n",
        "# aplicamos one-hot-encoding\n",
        "\n",
        "chromosome_indexes = [i for i,_ in enumerate(chromosome_classes)]\n",
        "\n",
        "chromosome_one_hot = tf.one_hot(chromosome_indexes, len(chromosome_indexes), dtype=float)\n",
        "\n",
        "genotypes_indexes = [i for i,_ in enumerate(genotypes_classes)]\n",
        "\n",
        "genotypes_one_hot = tf.one_hot(genotypes_indexes, len(genotypes_classes), dtype=float)\n",
        "\n",
        "# emparejamos las clases con su one hot\n",
        "\n",
        "chromosome_match = list(zip(chromosome_classes, chromosome_one_hot))\n",
        "genotypes_match = list(zip(genotypes_classes, genotypes_one_hot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQENkdhH8wxv"
      },
      "source": [
        "Ahora, debemos unir todos los datos y preparar las entradas y salidasd de la red y generar los conjuntos de prueba y entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnLI0guQ83eZ"
      },
      "source": [
        "# construimos las matrices de entrada\n",
        "\n",
        "dataset = list()\n",
        "\n",
        "for r, c, p, g in lines_to_rows:\n",
        "  for chromosome_oh in chromosome_match:\n",
        "    if c == chromosome_oh[0]:\n",
        "      if r[0] == 'r':\n",
        "        dataset.append((np.array([float(r[2:])] + chromosome_oh[1].numpy().tolist() + [float(p)]), g))\n",
        "      else:\n",
        "        dataset.append((np.array([float(r[1:])] + chromosome_oh[1].numpy().tolist() + [float(p)]), g))\n",
        "\n",
        "# tomamos el 80% del conjunto total como el conjunto de entrenamiento y el 20% el conjunto de prueba\n",
        "\n",
        "train_number = int(len(dataset) * 0.8)\n",
        "\n",
        "train_set = dataset[:train_number]\n",
        "test_set = dataset[train_number:]\n",
        "\n",
        "x_train = list()\n",
        "y_train = list()\n",
        "\n",
        "x_test = list()\n",
        "y_test = list()\n",
        "\n",
        "count = dict()\n",
        "\n",
        "for g in genotypes_classes:\n",
        "  count[g] = 0\n",
        "\n",
        "# definimos las clases del conjunto de prueba y entrenamiento\n",
        "\n",
        "for x,y in train_set:\n",
        "  for g, one_hot in genotypes_match:\n",
        "    if y == g:\n",
        "      count[g] += 1\n",
        "      y_train.append(np.array(one_hot))\n",
        "      x_train.append(x)\n",
        "\n",
        "for x,y in test_set:\n",
        "  for g, one_hot in genotypes_match:\n",
        "    if y == g:\n",
        "      count[g] += 1\n",
        "      y_test.append(np.array(one_hot))\n",
        "      x_test.append(x)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKYZ1akXM413"
      },
      "source": [
        "Podemos ver la gráfica de los genotipos y datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "cIuxCrTeM_I_",
        "outputId": "86a4119f-6dca-49d2-bdca-44d9b753f8a7"
      },
      "source": [
        "classes = list(count.keys())\n",
        "values = list(count.values())\n",
        "\n",
        "fig = plt.figure(figsize = (20, 10))\n",
        "plt.bar(classes, values, color ='maroon', width = 0.4) \n",
        "plt.xlabel(\"Genotipos\") \n",
        "plt.ylabel(\"Poblacion\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YML5TgrXJjg9"
      },
      "source": [
        "Como ya tenemos el conjunto de datos ya podemos iniciar la construcción de la red"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP-yyMSoJpxH",
        "outputId": "dbf27111-d244-493d-ce17-128fe5525789"
      },
      "source": [
        "# creación del modelo\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.h1 = nn.Linear(input_size, 50)\n",
        "    self.h2 = nn.ReLU()\n",
        "    self.h3 = nn.Linear(50, 100)\n",
        "    self.h4 = nn.ReLU()\n",
        "    self.h5 = nn.Linear(100, output_size)\n",
        "    self.h6 = nn.Dropout(0.5)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.h1(x)\n",
        "    x = self.h2(x)\n",
        "    x = self.h3(x)\n",
        "    x = self.h4(x)\n",
        "    x = self.h5(x)\n",
        "    x = self.h6(x)\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "\n",
        "x_train_tensor = pt.from_numpy(x_train.astype(np.float32))\n",
        "x_test_tensor = pt.from_numpy(x_test.astype(np.float32))\n",
        "y_train_tensor = pt.squeeze(pt.from_numpy(y_train).float())\n",
        "y_test_tensor = pt.squeeze(pt.from_numpy(y_test).float())\n",
        "model = Model(x_train_tensor.shape[1], y_train_tensor.shape[1])\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = pt.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "  return (y_true == y_pred).float().sum() / len(y_true)\n",
        "\n",
        "for epoch in range(100000):\n",
        "  y_pred = model(x_train_tensor)\n",
        "  y_pred = pt.squeeze(y_pred)\n",
        "  train_loss = criterion(y_pred, y_train_tensor)\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    train_acc = calculate_accuracy(y_train_tensor, y_pred)\n",
        "    y_test_pred = model(x_test_tensor)\n",
        "    y_test_pred = pt.squeeze(y_test_pred)\n",
        "    test_loss = criterion(y_test_pred, y_test_tensor)\n",
        "    test_acc = calculate_accuracy(y_test_tensor, y_test_pred)\n",
        "    print(f'''epoch {epoch}\n",
        "          Train set - loss: {train_loss}, accuracy: {train_acc}\n",
        "          Test  set - loss: {test_loss}, accuracy: {test_acc}\n",
        "          ''')\n",
        "    \n",
        "  optimizer.zero_grad()\n",
        "  train_loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "          Train set - loss: 0.723384439945221, accuracy: 17.99395179748535\n",
            "          Test  set - loss: 0.7231720685958862, accuracy: 17.998334884643555\n",
            "          \n",
            "epoch 100\n",
            "          Train set - loss: 0.7232838869094849, accuracy: 17.85231590270996\n",
            "          Test  set - loss: 0.7233351469039917, accuracy: 17.84882354736328\n",
            "          \n",
            "epoch 200\n",
            "          Train set - loss: 0.723274290561676, accuracy: 17.835590362548828\n",
            "          Test  set - loss: 0.7232972383499146, accuracy: 17.81887435913086\n",
            "          \n",
            "epoch 300\n",
            "          Train set - loss: 0.7232864499092102, accuracy: 17.839576721191406\n",
            "          Test  set - loss: 0.7233309149742126, accuracy: 17.818161010742188\n",
            "          \n",
            "epoch 400\n",
            "          Train set - loss: 0.7231642007827759, accuracy: 17.683162689208984\n",
            "          Test  set - loss: 0.7232621908187866, accuracy: 17.683618545532227\n",
            "          \n",
            "epoch 500\n",
            "          Train set - loss: 0.7231647372245789, accuracy: 17.691097259521484\n",
            "          Test  set - loss: 0.7232676148414612, accuracy: 17.680381774902344\n",
            "          \n",
            "epoch 600\n",
            "          Train set - loss: 0.7231650948524475, accuracy: 17.687297821044922\n",
            "          Test  set - loss: 0.723254382610321, accuracy: 17.682893753051758\n",
            "          \n",
            "epoch 700\n",
            "          Train set - loss: 0.723171055316925, accuracy: 17.688678741455078\n",
            "          Test  set - loss: 0.7232601642608643, accuracy: 17.682283401489258\n",
            "          \n",
            "epoch 800\n",
            "          Train set - loss: 0.723163902759552, accuracy: 17.687971115112305\n",
            "          Test  set - loss: 0.7232400178909302, accuracy: 17.686281204223633\n",
            "          \n",
            "epoch 900\n",
            "          Train set - loss: 0.7231770157814026, accuracy: 17.686141967773438\n",
            "          Test  set - loss: 0.7232584357261658, accuracy: 17.682340621948242\n",
            "          \n",
            "epoch 1000\n",
            "          Train set - loss: 0.7231643199920654, accuracy: 17.68482208251953\n",
            "          Test  set - loss: 0.7232436537742615, accuracy: 17.66456413269043\n",
            "          \n",
            "epoch 1100\n",
            "          Train set - loss: 0.7231618762016296, accuracy: 17.68268394470215\n",
            "          Test  set - loss: 0.7232372760772705, accuracy: 17.667903900146484\n",
            "          \n",
            "epoch 1200\n",
            "          Train set - loss: 0.7231630086898804, accuracy: 17.681764602661133\n",
            "          Test  set - loss: 0.7232339382171631, accuracy: 17.66979217529297\n",
            "          \n",
            "epoch 1300\n",
            "          Train set - loss: 0.7231671214103699, accuracy: 17.682437896728516\n",
            "          Test  set - loss: 0.7232513427734375, accuracy: 17.673147201538086\n",
            "          \n",
            "epoch 1400\n",
            "          Train set - loss: 0.7231678366661072, accuracy: 17.675613403320312\n",
            "          Test  set - loss: 0.7232421636581421, accuracy: 17.668804168701172\n",
            "          \n",
            "epoch 1500\n",
            "          Train set - loss: 0.7231714725494385, accuracy: 17.677745819091797\n",
            "          Test  set - loss: 0.7232288122177124, accuracy: 17.679859161376953\n",
            "          \n",
            "epoch 1600\n",
            "          Train set - loss: 0.7231653928756714, accuracy: 17.683502197265625\n",
            "          Test  set - loss: 0.7232179641723633, accuracy: 17.66823959350586\n",
            "          \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-197-9b6ca0c9d349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-197-9b6ca0c9d349>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
